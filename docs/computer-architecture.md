# 01. 컴퓨터 구조 (Computer Architecture)

---

## 1. 컴퓨터 구조 기본 개념

### ⭕ 폰 노이만 구조란? ◑

폰 노이만 구조(Von Neumann Architecture)는 현대 컴퓨터의 기본 설계 원리이다. 1945년 존 폰 노이만이 제안했다.

**핵심 특징:**
1. **저장 프로그램 방식**: 프로그램과 데이터가 같은 메모리에 저장
2. **순차적 실행**: 명령어를 순차적으로 fetch → decode → execute
3. **단일 버스**: CPU와 메모리 사이에 하나의 버스 사용

```
폰 노이만 구조:

                   ┌─────────────────────────────────┐
                   │              CPU                 │
                   │  ┌─────────┐    ┌─────────┐    │
                   │  │ Control │    │   ALU   │    │
                   │  │  Unit   │    │         │    │
                   │  └─────────┘    └─────────┘    │
                   │       ▲              ▲          │
                   │       └──────┬───────┘          │
                   │              │ (레지스터)        │
                   └──────────────┼──────────────────┘
                                  │
                            시스템 버스
                   (주소 버스 / 데이터 버스 / 제어 버스)
                                  │
                   ┌──────────────┴──────────────┐
                   │                              │
            ┌──────┴──────┐              ┌───────┴───────┐
            │   Memory    │              │    I/O        │
            │ (프로그램 +  │              │   Devices     │
            │   데이터)   │              │               │
            └─────────────┘              └───────────────┘
```

**폰 노이만 병목 (Von Neumann Bottleneck):**

CPU와 메모리 사이의 단일 버스로 인해 데이터 전송이 병목이 된다. CPU 속도는 빠르게 발전했지만 메모리 접근 속도는 상대적으로 느려서 CPU가 데이터를 기다리는 시간이 늘어난다.

```
CPU 발전 vs 메모리 발전:

성능 │
     │     CPU ──────────────────────╱╱
     │                           ╱╱
     │                       ╱╱
     │                   ╱╱  ← 성능 격차 (메모리 벽)
     │   메모리 ────────────────────
     │
     └──────────────────────────────▶ 시간
```

**해결 방법:**
- 캐시 메모리 도입
- 멀티코어 프로세서
- 메모리 대역폭 증가 (DDR, HBM)

### 하버드 구조 ◑

폰 노이만 구조와 달리, 명령어와 데이터를 별도의 메모리에 저장하고 별도의 버스를 사용한다.

```
하버드 구조:

                        ┌─────────┐
                        │   CPU   │
                        └────┬────┘
                             │
              ┌──────────────┼──────────────┐
              │              │              │
      ┌───────┴───────┐           ┌───────┴───────┐
      │ 명령어 메모리  │           │ 데이터 메모리  │
      │ (Instruction) │           │   (Data)      │
      └───────────────┘           └───────────────┘
         명령어 버스                  데이터 버스
```

**장점:**
- 명령어와 데이터를 동시에 읽을 수 있음
- 메모리 대역폭 2배
- 폰 노이만 병목 해소

**사용처:**
- DSP (디지털 신호 처리기)
- 마이크로컨트롤러
- 현대 CPU의 L1 캐시 (분리된 I-cache, D-cache)

### 메모리 계층 구조 ◑

메모리 계층 구조는 속도와 비용의 트레이드오프를 활용하여 성능을 최적화한다.

```
메모리 계층:

         ▲ 속도 빠름                           ▲ 비용 높음
         │  용량 작음                           │
         │                                     │
    ┌────┴────────────────────────────────────┐
    │     레지스터 (CPU 내부)  ~1 KB           │
    ├─────────────────────────────────────────┤
    │        L1 캐시  ~32-64 KB               │
    ├─────────────────────────────────────────┤
    │        L2 캐시  ~256 KB - 1 MB          │
    ├─────────────────────────────────────────┤
    │        L3 캐시  ~8-64 MB                │
    ├─────────────────────────────────────────┤
    │     메인 메모리 (RAM)  ~16-128 GB       │
    ├─────────────────────────────────────────┤
    │    보조 저장장치 (SSD/HDD)  ~TB         │
    └─────────────────────────────────────────┘
         │                                     │
         ▼ 속도 느림                           ▼ 비용 낮음
            용량 큼
```

| 계층 | 접근 시간 | 용량 | 기술 |
|------|-----------|------|------|
| 레지스터 | ~0.5 ns | ~1 KB | 플립플롭 |
| L1 캐시 | ~1 ns | ~64 KB | SRAM |
| L2 캐시 | ~3-5 ns | ~256 KB | SRAM |
| L3 캐시 | ~10-20 ns | ~8-64 MB | SRAM |
| 메인 메모리 | ~50-100 ns | ~16-128 GB | DRAM |
| SSD | ~50-150 μs | ~TB | Flash NAND |
| HDD | ~5-10 ms | ~TB | 자기 디스크 |

---

## 2. 캐시 (Cache) ◑

### 캐시란? ◑

캐시는 CPU와 메인 메모리 사이에 위치한 고속 메모리로, 자주 사용하는 데이터를 저장하여 메모리 접근 시간을 줄인다.

**지역성 원리 (Principle of Locality):**

캐시가 효과적인 이유는 프로그램이 지역성을 보이기 때문이다.

| 지역성 | 설명 | 예시 |
|--------|------|------|
| **시간적 지역성** | 최근 접근한 데이터를 다시 접근할 가능성 높음 | 루프 변수, 자주 호출되는 함수 |
| **공간적 지역성** | 접근한 데이터 근처를 접근할 가능성 높음 | 배열 순회, 순차적 명령어 |

```c
// 공간적 지역성 예시: 배열 순차 접근
for (int i = 0; i < N; i++) {
    sum += array[i];  // 연속된 메모리 접근
}

// 시간적 지역성 예시: 루프 변수
for (int i = 0; i < 1000; i++) {
    sum += i;  // i를 반복해서 접근
}
```

### ⭕ 캐시 매핑 방식을 설명하라

메모리 블록이 캐시의 어느 위치에 저장될지 결정하는 방식이다.

**1. Direct Mapped (직접 매핑)**

각 메모리 블록이 캐시의 특정 한 위치에만 저장될 수 있다.

```
메모리 주소 → 캐시 인덱스: (주소 / 블록 크기) mod (캐시 라인 수)

예: 캐시 라인 4개, 블록 크기 16 bytes

메모리 블록 0, 4, 8, 12, ... → 캐시 라인 0
메모리 블록 1, 5, 9, 13, ... → 캐시 라인 1
메모리 블록 2, 6, 10, 14, ... → 캐시 라인 2
메모리 블록 3, 7, 11, 15, ... → 캐시 라인 3

주소 구성:
┌───────────┬─────────┬────────┐
│    Tag    │  Index  │ Offset │
│  (n bits) │ (k bits)│(b bits)│
└───────────┴─────────┴────────┘
```

- **장점**: 구현 간단, 접근 빠름
- **단점**: 충돌 미스가 많음 (같은 인덱스에 매핑되는 블록들)

**2. Fully Associative (완전 연관)**

메모리 블록이 캐시의 어느 위치에든 저장될 수 있다.

```
┌───────────────────┐
│ 캐시 라인 0        │ ← 어떤 블록이든 저장 가능
│ 캐시 라인 1        │
│ 캐시 라인 2        │
│ 캐시 라인 3        │
└───────────────────┘

주소 구성:
┌─────────────────┬────────┐
│       Tag       │ Offset │
│    (m bits)     │(b bits)│
└─────────────────┴────────┘
```

- **장점**: 충돌 미스 최소화
- **단점**: 모든 태그와 비교해야 함 → 비교기 많이 필요, 느림

**3. Set Associative (세트 연관)**

캐시를 여러 세트로 나누고, 각 세트 내에서는 자유롭게 매핑한다.

```
N-way Set Associative: 각 세트에 N개의 캐시 라인

예: 2-way Set Associative

Set 0: │ 라인 0 │ 라인 1 │  ← 블록 0, 4, 8, ... 중 2개
Set 1: │ 라인 0 │ 라인 1 │  ← 블록 1, 5, 9, ... 중 2개
Set 2: │ 라인 0 │ 라인 1 │
Set 3: │ 라인 0 │ 라인 1 │

주소 구성:
┌───────────┬────────────┬────────┐
│    Tag    │ Set Index  │ Offset │
│  (n bits) │  (k bits)  │(b bits)│
└───────────┴────────────┴────────┘
```

| 방식 | 설명 | 장점 | 단점 |
|------|------|------|------|
| **Direct Mapped** | 1-way | 간단, 빠름 | 충돌 미스 많음 |
| **Fully Associative** | All-way | 충돌 미스 최소 | 비교기 많음, 느림 |
| **N-way Set Associative** | 세트 내 N개 | 절충안 | 적당한 복잡도 |

**현대 CPU의 캐시:**
- L1: 8-way 또는 4-way
- L2: 8-way
- L3: 16-way 또는 그 이상

### 캐시 교체 정책 ◑

세트가 가득 찼을 때 어떤 라인을 교체할지 결정한다.

| 정책 | 설명 | 장단점 |
|------|------|--------|
| **LRU** | 가장 오래 사용 안 된 라인 | 정확하지만 구현 복잡 |
| **Pseudo-LRU** | 근사 LRU | 구현 간단 |
| **FIFO** | 가장 먼저 들어온 라인 | 간단하지만 비효율적 |
| **Random** | 무작위 선택 | 간단, 의외로 효과적 |

### ⭕ Write-through와 Write-back의 차이는?

캐시에 쓰기 연산이 발생했을 때 메모리에 언제 반영할지 결정한다.

```
Write-through:
  CPU ─ 쓰기 ─▶ 캐시 ─ 즉시 쓰기 ─▶ 메모리
                   │
                   └─ 캐시와 메모리 항상 동기화

Write-back:
  CPU ─ 쓰기 ─▶ 캐시 (Dirty bit = 1)
                   │
                   └─ 나중에 (교체 시) ─▶ 메모리
```

| 정책 | 동작 | 장점 | 단점 |
|------|------|------|------|
| **Write-through** | 캐시와 메모리 동시 쓰기 | 일관성 유지 쉬움, 구현 간단 | 쓰기 느림, 메모리 대역폭 소비 |
| **Write-back** | 캐시만 쓰고 나중에 메모리 갱신 | 쓰기 빠름, 대역폭 절약 | Dirty bit 필요, 일관성 복잡 |

**Write-allocate vs No-write-allocate:**
- **Write-allocate**: 쓰기 미스 시 블록을 캐시에 로드 후 쓰기
- **No-write-allocate**: 쓰기 미스 시 메모리에 직접 쓰기

일반적인 조합:
- Write-back + Write-allocate
- Write-through + No-write-allocate

### 캐시 미스 유형 (3C) ◑

| 유형 | 설명 | 해결 방법 |
|------|------|-----------|
| **Compulsory (Cold)** | 최초 접근 시 발생 | 프리페칭, 더 큰 블록 |
| **Capacity** | 캐시 용량 부족 | 캐시 용량 증가 |
| **Conflict** | 같은 세트에 매핑되어 충돌 | 연관도 증가 |

### ⭕ 캐시 일관성 (Cache Coherence)이란?

멀티코어 시스템에서 여러 캐시가 동일 메모리 위치를 캐싱할 때 일관성을 유지하는 것이다.

```
문제 상황:

    Core 1 캐시         Core 2 캐시
    ┌─────────┐        ┌─────────┐
    │ x = 10  │        │ x = 10  │
    └─────────┘        └─────────┘
          │                  │
    Core 1이 x = 20으로 수정하면?
          │
    ┌─────────┐        ┌─────────┐
    │ x = 20  │        │ x = 10  │  ← 불일치!
    └─────────┘        └─────────┘
```

**MESI 프로토콜:**

캐시 라인의 상태를 4가지로 관리한다.

| 상태 | 의미 | 메모리와 일치 | 다른 캐시에 존재 |
|------|------|---------------|------------------|
| **M**odified | 수정됨, 이 캐시에만 존재 | X | X |
| **E**xclusive | 수정 안 됨, 이 캐시에만 존재 | O | X |
| **S**hared | 수정 안 됨, 여러 캐시에 존재 | O | O |
| **I**nvalid | 무효 상태 | - | - |

```
MESI 상태 전이 예시:

1. Core1이 x 읽음
   Core1: I → E (Exclusive, 혼자 가지고 있음)

2. Core2도 x 읽음 (스누핑으로 Core1이 감지)
   Core1: E → S (Shared)
   Core2: I → S (Shared)

3. Core1이 x = 20으로 수정
   Core1: S → M (Modified)
   Core2: S → I (Invalid, 무효화)

4. Core2가 x 읽으려 함
   Core1: M → S (메모리에 쓰고 공유)
   Core2: I → S (메모리에서 읽음)
```

**스누핑 (Snooping):**
- 각 캐시가 버스를 감시하여 다른 캐시의 접근을 감지
- 소규모 멀티프로세서에 적합

**디렉토리 기반:**
- 중앙 디렉토리가 각 블록의 위치를 추적
- 대규모 시스템에 적합 (버스 트래픽 감소)

---

## 3. 파이프라이닝

### 파이프라이닝이란? ◑

명령어 실행을 여러 단계로 나누고, 각 단계를 동시에 수행하여 처리량(throughput)을 높이는 기법이다.

```
파이프라인 없이 (순차 실행):

명령어 1: │ IF │ ID │ EX │ MEM │ WB │
명령어 2:                          │ IF │ ID │ EX │ MEM │ WB │
                                                           │ IF │ ...
시간 ────────────────────────────────────────────────────────▶
          5 사이클         5 사이클        ...


파이프라인 사용:

명령어 1: │ IF │ ID │ EX │ MEM │ WB │
명령어 2:      │ IF │ ID │ EX  │ MEM │ WB │
명령어 3:           │ IF │ ID  │ EX  │ MEM │ WB │
명령어 4:                │ IF  │ ID  │ EX  │ MEM │ WB │
          ────────────────────────────────────────────▶
          채움 후 매 사이클 1개 명령어 완료!
```

**이상적인 경우**: N단계 파이프라인은 처리량을 N배 향상

### 파이프라인 5단계 (MIPS 기준)

```
┌────┐   ┌────┐   ┌────┐   ┌────┐   ┌────┐
│ IF │ → │ ID │ → │ EX │ → │MEM │ → │ WB │
└────┘   └────┘   └────┘   └────┘   └────┘
   │        │        │        │        │
명령어   레지스터   ALU      메모리   레지스터
 인출     해독     연산      접근     쓰기
```

| 단계 | 이름 | 동작 |
|------|------|------|
| **IF** | Instruction Fetch | PC가 가리키는 명령어를 메모리에서 인출 |
| **ID** | Instruction Decode | 명령어 해독, 레지스터 값 읽기 |
| **EX** | Execute | ALU 연산, 분기 주소 계산 |
| **MEM** | Memory Access | 메모리 읽기/쓰기 (LOAD/STORE) |
| **WB** | Write Back | 결과를 레지스터에 저장 |

### ⭕ 파이프라인 해저드란 무엇이고, 어떤 종류가 있는가?

파이프라인 해저드는 다음 명령어를 예정대로 실행할 수 없는 상황이다.

**1. 구조적 해저드 (Structural Hazard)**

여러 명령어가 같은 하드웨어 자원을 동시에 사용하려 할 때 발생한다.

```
예: 단일 메모리 포트

명령어 1:      │ IF │ ID │ EX │ MEM │ WB │
명령어 4:                      │ IF  │ ...  ← 메모리 충돌!
                                  ↑
                              MEM과 IF가 동시에 메모리 접근
```

**해결**: 자원 추가 (별도의 명령어 캐시와 데이터 캐시)

**2. 데이터 해저드 (Data Hazard)**

명령어 간 데이터 의존성으로 인해 발생한다.

```
ADD R1, R2, R3    ; R1 = R2 + R3
SUB R4, R1, R5    ; R4 = R1 - R5 (R1 필요!)
         │
         └── R1 값이 아직 쓰여지지 않음

타이밍:
ADD: │ IF │ ID │ EX │ MEM │ WB │ ← R1에 쓰기
SUB:      │ IF │ ID │ ...       ← R1 읽기 필요!
                   ↑
              R1 값이 아직 없음
```

**해결 방법:**
- **스톨 (Stall/Bubble)**: 파이프라인 정지
- **포워딩 (Forwarding/Bypassing)**: EX 결과를 바로 전달
- **컴파일러 최적화**: 명령어 순서 재배치

```
포워딩:

ADD: │ IF │ ID │ EX │ MEM │ WB │
                 │
                 └─────▶ (ALU 결과를 바로 전달)
SUB:      │ IF │ ID │ EX │ MEM │ WB │
                   ↑
              포워딩으로 스톨 없이 진행
```

**데이터 해저드 세부 유형:**

| 유형 | 설명 | 해결 |
|------|------|------|
| **RAW** (Read After Write) | 이전 명령어의 결과 필요 | 포워딩, 스톨 |
| **WAR** (Write After Read) | 비순차 실행에서 발생 | 레지스터 리네이밍 |
| **WAW** (Write After Write) | 비순차 실행에서 발생 | 레지스터 리네이밍 |

**3. 제어 해저드 (Control Hazard)**

분기 명령어로 인해 다음 실행할 명령어가 불확실할 때 발생한다.

```
BEQ R1, R2, LABEL  ; 분기 (R1 == R2이면 LABEL로)
ADD ...            ; 분기 결과에 따라 실행 여부 결정
SUB ...
...
LABEL: ...

문제:
BEQ: │ IF │ ID │ EX │ MEM │ WB │
                 ↑
            분기 결정 (EX 단계)
ADD:      │ IF │ ID │ ???
              ↑
        이미 인출했는데, 실행해야 하나?
```

**해결 방법:**
- **스톨**: 분기 결과까지 대기 (비효율적)
- **지연 분기**: 분기 후 슬롯에 독립적 명령어 배치
- **분기 예측**: 결과를 예측하고 투기적 실행

### ⭕ 분기 예측 (Branch Prediction) ◑

분기 명령어의 결과를 미리 예측하여 파이프라인 스톨을 줄이는 기법이다.

**정적 예측 vs 동적 예측:**

| 구분 | 정적 예측 | 동적 예측 |
|------|-----------|-----------|
| 방식 | 컴파일 타임 결정 | 실행 히스토리 기반 |
| 정확도 | ~60-70% | ~90% 이상 |
| 예시 | Always Taken, BTFNT | 2-bit Predictor |

**BTFNT (Backward Taken, Forward Not Taken):**
- 뒤로 분기 (루프) → Taken 예측
- 앞으로 분기 (조건문) → Not Taken 예측

**2-bit Saturating Counter:**

```
상태 전이:

       예측 실패        예측 실패
            ↓              ↓
┌────────────────────────────────────────────┐
│                                            │
│  ┌──────────┐      ┌──────────┐            │
│  │ Strongly │ ─────▶│  Weakly  │            │
│  │  Taken   │◀───── │  Taken   │            │
│  └──────────┘      └──────────┘            │
│       ▲                  │                 │
│       │              예측 실패              │
│   예측 성공              ▼                 │
│       │            ┌──────────┐            │
│       │            │  Weakly  │            │
│       └───────────│Not Taken │            │
│                    └──────────┘            │
│                          │                 │
│                      예측 실패              │
│                          ▼                 │
│                    ┌──────────┐            │
│                    │ Strongly │            │
│                    │Not Taken │            │
│                    └──────────┘            │
└────────────────────────────────────────────┘
```

- 예측 실패가 2번 연속되어야 예측 방향 변경
- 루프 마지막 반복에서만 오예측 발생

**BTB (Branch Target Buffer):**
- 분기 목적지 주소를 캐싱하는 테이블
- 분기 명령어 fetch 시 함께 조회하여 지연 최소화

---

## 4. CPU 발전 과정

### ⭕ CISC와 RISC의 차이는?

| 구분 | CISC | RISC |
|------|------|------|
| 명령어 | 복잡하고 다양함 | 단순하고 적음 |
| 명령어 길이 | 가변 길이 | 고정 길이 |
| 실행 | 명령어당 여러 사이클 | 파이프라이닝 최적화 (1 IPC 목표) |
| 메모리 접근 | 다양한 주소 지정 모드 | LOAD-STORE 아키텍처 |
| 레지스터 | 적음 | 많음 (32개 이상) |
| 디코딩 | 복잡 | 간단 |
| 예시 | x86, x86-64 | ARM, MIPS, RISC-V |

```
CISC 예시 (x86):
ADD [mem], R1    ; 메모리에서 읽고, 더하고, 메모리에 쓰기

RISC 예시 (ARM):
LDR R2, [mem]    ; 메모리 → 레지스터
ADD R2, R2, R1   ; 레지스터 연산
STR R2, [mem]    ; 레지스터 → 메모리
```

**현대 CPU:**

x86 CPU는 내부적으로 CISC 명령어를 RISC 유사 마이크로옵(μops)으로 변환하여 실행한다.

```
x86 명령어 ──▶ 디코더 ──▶ μops ──▶ RISC 스타일 실행 엔진
```

### RISC의 특징 ◑

1. **LOAD-STORE 아키텍처**: 메모리 접근은 오직 LOAD/STORE 명령어만
2. **고정 길이 명령어**: 디코딩 단순화, 파이프라이닝에 유리
3. **많은 범용 레지스터**: 메모리 접근 최소화
4. **단순한 주소 지정 모드**: 하드웨어 단순화

### ⭕ 슈퍼스칼라와 비순차 실행 ◑

**슈퍼스칼라 (Superscalar):**

한 사이클에 여러 명령어를 동시에 발행/실행하는 구조이다.

```
4-wide 슈퍼스칼라:

              ┌────────────────────────────────────┐
              │            Fetch Unit               │
              │   (한 사이클에 4개 명령어 인출)       │
              └────────────────────────────────────┘
                               │
                               ▼
              ┌────────────────────────────────────┐
              │           Decode Unit               │
              │   (4개 명령어 동시 디코드)           │
              └────────────────────────────────────┘
                               │
          ┌────────────────────┼────────────────────┐
          │          │         │          │         │
          ▼          ▼         ▼          ▼         │
       ┌─────┐   ┌─────┐   ┌─────┐   ┌─────┐       │
       │ ALU │   │ ALU │   │ FPU │   │Load │       │
       └─────┘   └─────┘   └─────┘   │Store│       │
                                     └─────┘       │
```

**비순차 실행 (Out-of-Order Execution):**

데이터 의존성이 없는 명령어를 먼저 실행하여 파이프라인 활용도를 높인다.

```
프로그램 순서:
1. ADD R1, R2, R3    ; R1 = R2 + R3
2. SUB R4, R1, R5    ; R4 = R1 - R5 (1번 결과 필요)
3. MUL R6, R7, R8    ; R6 = R7 * R8 (독립적!)
4. DIV R9, R6, R10   ; R9 = R6 / R10 (3번 결과 필요)

비순차 실행:
1. ADD R1, R2, R3    ; 실행
3. MUL R6, R7, R8    ; 1, 2와 독립적이므로 먼저 실행!
2. SUB R4, R1, R5    ; 1번 결과 준비되면 실행
4. DIV R9, R6, R10   ; 3번 결과 준비되면 실행
```

**비순차 실행 구성 요소:**

| 구성 요소 | 역할 |
|-----------|------|
| **Reservation Station** | 피연산자 대기, 준비되면 실행 유닛으로 발행 |
| **Register Renaming** | WAR, WAW 해저드 제거 (물리 레지스터 할당) |
| **Reorder Buffer (ROB)** | 순서대로 커밋, 정확한 예외 처리 보장 |

```
비순차 실행 파이프라인:

Fetch → Decode → Rename → Dispatch → Issue → Execute → Writeback → Commit
                   │                    │                           │
              레지스터              Reservation                    ROB
              리네이밍               Station                   (순서 복원)
```

---

## 5. 컴파일 과정

### 프로그래밍 언어의 발전

```
1세대: 기계어 (0과 1)
     ↓
2세대: 어셈블리어 (니모닉)
     ↓
3세대: 고급 언어 (C, Fortran, COBOL)
     ↓
4세대: 도메인 특화 (SQL, MATLAB)
     ↓
5세대: AI/선언형 (Prolog, Lisp)
```

### ⭕ 컴파일 과정을 설명하라

```
소스 코드 (.c)
     │
     ▼
┌─────────────────────────────────────────────┐
│  1. 전처리 (Preprocessing)                   │
│     - #include, #define 처리                │
│     - 출력: 확장된 소스 코드                 │
└─────────────────────────────────────────────┘
     │
     ▼
┌─────────────────────────────────────────────┐
│  2. 어휘 분석 (Lexical Analysis)             │
│     - 토큰으로 분리                          │
│     - 출력: 토큰 스트림                      │
└─────────────────────────────────────────────┘
     │
     ▼
┌─────────────────────────────────────────────┐
│  3. 구문 분석 (Syntax Analysis)              │
│     - 문법 검사, 파싱                        │
│     - 출력: 파싱 트리 (AST)                  │
└─────────────────────────────────────────────┘
     │
     ▼
┌─────────────────────────────────────────────┐
│  4. 의미 분석 (Semantic Analysis)            │
│     - 타입 검사, 의미 검증                   │
│     - 출력: 심볼 테이블                      │
└─────────────────────────────────────────────┘
     │
     ▼
┌─────────────────────────────────────────────┐
│  5. 중간 코드 생성 (IR Generation)           │
│     - 플랫폼 독립적 표현                     │
│     - 출력: IR (SSA, 3-address code)        │
└─────────────────────────────────────────────┘
     │
     ▼
┌─────────────────────────────────────────────┐
│  6. 최적화 (Optimization)                    │
│     - 코드 효율성 개선                       │
│     - 루프 최적화, 상수 폴딩, 인라이닝       │
└─────────────────────────────────────────────┘
     │
     ▼
┌─────────────────────────────────────────────┐
│  7. 코드 생성 (Code Generation)              │
│     - 타겟 기계어 생성                       │
│     - 레지스터 할당                          │
│     - 출력: 목적 파일 (.o, .obj)            │
└─────────────────────────────────────────────┘
     │
     ▼
목적 파일 (.o)
```

**각 단계 상세:**

| 단계 | 입력 | 출력 | 주요 작업 |
|------|------|------|-----------|
| 어휘 분석 | 소스 코드 | 토큰 | 식별자, 키워드, 연산자 분리 |
| 구문 분석 | 토큰 | AST | 문법 규칙 적용, 구조 파악 |
| 의미 분석 | AST | 어노테이트된 AST | 타입 체크, 변수 선언 확인 |
| IR 생성 | AST | IR | 중간 표현 생성 |
| 최적화 | IR | 최적화된 IR | 불필요한 코드 제거, 성능 개선 |
| 코드 생성 | IR | 어셈블리/기계어 | 레지스터 할당, 명령어 선택 |

---

## 6. 링커와 로더

### 링커 (Linker) ◑

여러 목적 파일을 하나의 실행 파일로 연결한다.

```
┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│   main.o     │  │   utils.o    │  │  libc.a      │
│   ┌────────┐ │  │   ┌────────┐ │  │  (라이브러리) │
│   │ .text  │ │  │   │ .text  │ │  │              │
│   │ .data  │ │  │   │ .data  │ │  │              │
│   │ .bss   │ │  │   │ .bss   │ │  │              │
│   └────────┘ │  │   └────────┘ │  │              │
└──────┬───────┘  └──────┬───────┘  └──────┬───────┘
       │                 │                 │
       └─────────────────┼─────────────────┘
                         │
                         ▼
                    ┌─────────┐
                    │  Linker │
                    └────┬────┘
                         │
                         ▼
               ┌──────────────────┐
               │   a.out (실행 파일) │
               │   ┌─────────────┐  │
               │   │   .text     │  │
               │   │   .data     │  │
               │   │   .bss      │  │
               │   └─────────────┘  │
               └──────────────────┘
```

**링커의 역할:**
1. **심볼 해석 (Symbol Resolution)**: 외부 참조를 정의와 연결
2. **재배치 (Relocation)**: 상대 주소를 절대 주소로 변환
3. **섹션 병합**: 같은 타입의 섹션을 합침

**정적 링킹 vs 동적 링킹:**

| 구분 | 정적 링킹 | 동적 링킹 |
|------|-----------|-----------|
| 시점 | 컴파일 시 | 실행 시 |
| 파일 크기 | 큼 | 작음 |
| 라이브러리 갱신 | 재컴파일 필요 | 재컴파일 불필요 |
| 확장자 | .a (Linux), .lib (Windows) | .so (Linux), .dll (Windows) |

### 로더 (Loader) ◑

실행 파일을 메모리에 적재하고 실행 준비를 한다.

**로더의 역할:**
1. 실행 파일 읽기
2. 메모리 공간 할당
3. 코드/데이터 적재
4. 동적 링킹 수행 (필요시)
5. 스택/힙 초기화
6. 제어권 전달 (main 또는 _start)

---

## 7. 가상 주소와 메모리 구조

### ⭕ 프로세스 메모리 구조 ◑

```
높은 주소 (0xFFFFFFFF...)
┌─────────────────────────────────────┐
│             커널 영역               │  ← 사용자 접근 불가
├─────────────────────────────────────┤
│              Stack                  │  ← 지역 변수, 함수 호출 정보
│                ↓                    │     (높은 주소에서 낮은 주소로 성장)
│            (자유 공간)               │
│                ↑                    │
│              Heap                   │  ← 동적 할당 (malloc, new)
│                                     │     (낮은 주소에서 높은 주소로 성장)
├─────────────────────────────────────┤
│            BSS (.bss)               │  ← 초기화되지 않은 전역/정적 변수
├─────────────────────────────────────┤
│           Data (.data)              │  ← 초기화된 전역/정적 변수
├─────────────────────────────────────┤
│           Text (.text)              │  ← 실행 코드 (Read-only)
└─────────────────────────────────────┘
낮은 주소 (0x00000000...)
```

| 영역 | 내용 | 특징 |
|------|------|------|
| **Text** | 프로그램 코드 | 읽기 전용, 공유 가능 |
| **Data** | 초기화된 전역 변수 | `int g = 10;` |
| **BSS** | 초기화 안 된 전역 변수 | `int g;` (0으로 초기화) |
| **Heap** | 동적 할당 메모리 | `malloc()`, `new` |
| **Stack** | 지역 변수, 리턴 주소 | 함수 호출 시 사용 |

### 가상 메모리 ◑

**가상 메모리의 장점:**
1. **프로세스 격리**: 각 프로세스가 독립된 주소 공간
2. **물리 메모리보다 큰 공간**: 디스크를 확장 메모리로 사용
3. **메모리 보호**: 잘못된 접근 차단

```
가상 주소 → 물리 주소 변환:

Process A          Process B
┌─────────┐       ┌─────────┐
│ 가상    │       │ 가상    │
│ 주소    │       │ 주소    │
│ 공간    │       │ 공간    │
└────┬────┘       └────┬────┘
     │                 │
     │    MMU (Page Table)
     │                 │
     ▼                 ▼
┌────────────────────────────────┐
│          물리 메모리            │
└────────────────────────────────┘
```

---

## 8. GPU와 병렬 처리 ◑

### ⭕ CPU와 GPU의 차이는?

```
CPU 구조:                          GPU 구조:

┌──────────────────────┐           ┌──────────────────────────────┐
│  코어 1    코어 2    │           │ ┌─┐┌─┐┌─┐┌─┐ ... (수천 개)    │
│  ┌────┐   ┌────┐    │           │ └─┘└─┘└─┘└─┘                  │
│  │    │   │    │    │           │ ┌─┐┌─┐┌─┐┌─┐ ...              │
│  └────┘   └────┘    │           │ └─┘└─┘└─┘└─┘                  │
│                      │           │ ┌─┐┌─┐┌─┐┌─┐ ...              │
│  큰 캐시   큰 캐시   │           │ └─┘└─┘└─┘└─┘                  │
│  제어 로직 풍부      │           │                               │
└──────────────────────┘           │  작은 캐시, 단순 제어         │
                                   └──────────────────────────────┘

CPU: 소수의 강력한 코어           GPU: 수천 개의 단순한 코어
→ 순차 처리, 복잡한 로직          → 병렬 처리, 동일 연산 반복
```

| 구분 | CPU | GPU |
|------|-----|-----|
| 코어 수 | 소수 (4~64) | 수천 개 (1000~10000+) |
| 코어 특성 | 복잡, 고성능, 독립적 | 단순, 저성능, 협력적 |
| 적합 작업 | 순차 처리, 복잡한 로직 | 병렬 처리, 동일 연산 대량 수행 |
| 캐시 | 코어당 큰 캐시 | 작은 공유 캐시 |
| 메모리 | 시스템 메모리 (DDR) | 전용 메모리 (GDDR, HBM) |
| 지연 시간 | 낮음 (개별 작업 빠름) | 높음 (처리량 우선) |

### GPU 아키텍처 기본 ◑

```
NVIDIA GPU 구조:

GPU
├── GPC (Graphics Processing Cluster) × N
│   ├── SM (Streaming Multiprocessor) × M
│   │   ├── CUDA Core / Shader Unit × K
│   │   ├── Tensor Core (AI 전용)
│   │   ├── Warp Scheduler
│   │   ├── Shared Memory
│   │   └── L1 Cache
│   └── Rasterizer
├── L2 Cache (공유)
└── VRAM (Global Memory)
```

**주요 개념:**

| 용어 | 설명 |
|------|------|
| **SM** | 기본 연산 유닛, 여러 CUDA 코어 포함 |
| **Warp** | 32개 스레드가 동시에 같은 명령 실행 |
| **SIMT** | Single Instruction, Multiple Threads |
| **Global Memory** | 전체 GPU가 접근 가능한 메모리 (느림) |
| **Shared Memory** | SM 내 스레드 공유 (빠름) |

### GPU 활용 분야 ◑

| 분야 | 설명 |
|------|------|
| **그래픽스** | 3D 렌더링, 셰이딩 |
| **GPGPU** | 범용 연산 (CUDA, OpenCL) |
| **AI/ML** | 딥러닝 학습 및 추론 |
| **과학 계산** | 시뮬레이션, 분자 역학 |
| **암호화폐** | 채굴 연산 |

---

## 9. 메모리 하드웨어 ◑

### ⭕ SRAM과 DRAM의 차이는?

```
SRAM (6T 셀):                    DRAM (1T1C 셀):

    Vdd                              Word Line
     │                                   │
    ─┴─                             ┌────┴────┐
   ┌───┐                            │         │
   │   │←→ 2개의 교차                │  ┌───┐  │
   │   │   연결된 인버터             │  │ C │  │
   └───┘   (플립플롭)                │  └───┘  │
     │                              │    │    │
   ─┬─                              │  Bit    │
    Bit Line                        │  Line   │
                                    └─────────┘
                                    (커패시터에 저장)
```

| 구분 | SRAM | DRAM |
|------|------|------|
| 구조 | 6개 트랜지스터 (플립플롭) | 1 트랜지스터 + 1 커패시터 |
| 속도 | 빠름 (~1-10 ns) | 느림 (~50-100 ns) |
| 밀도 | 낮음 | 높음 (6배 이상) |
| 비용 | 비쌈 | 저렴 |
| 리프레시 | 불필요 | 필요 (주기적, ~64ms) |
| 전력 | 대기 중 낮음 | 리프레시로 소비 |
| 용도 | 캐시 메모리 | 메인 메모리 |

### 메모리 종류 ◑

| 종류 | 특징 | 용도 |
|------|------|------|
| **SDRAM** | 클럭 동기화 DRAM | 과거 메인 메모리 |
| **DDR SDRAM** | Double Data Rate (클럭 상승/하강 모두 전송) | 현재 메인 메모리 |
| **DDR4** | 1.2V, 3200 MT/s | 현재 주류 |
| **DDR5** | 1.1V, 6400+ MT/s, On-die ECC | 최신 세대 |
| **GDDR** | 그래픽용, 높은 대역폭 | GPU 메모리 |
| **HBM** | 3D 적층, 초고대역폭 (1 TB/s+) | 고성능 GPU, AI 가속기 |

### 메모리 대역폭과 레이턴시 ◑

```
예시:

DDR5-6400:
- 대역폭: 6400 MT/s × 8 bytes = 51.2 GB/s (채널당)
- 레이턴시: ~14 ns (약 90 클럭 사이클)

HBM3:
- 대역폭: ~800 GB/s 이상 (전체)
- 스택 구조로 핀 수 증가 없이 대역폭 확보
```

---

## 10. 버스와 I/O ◑

### 버스 (Bus) ◑

컴퓨터 내부에서 데이터를 전송하는 통로이다.

```
버스 구조:

           ┌─────────┐
           │   CPU   │
           └────┬────┘
                │
    ┌───────────┼───────────┐
    │     시스템 버스        │
    │  (주소/데이터/제어)     │
    └───────────┼───────────┘
                │
    ┌───────────┴───────────┐
    │                       │
┌───┴───┐               ┌───┴───┐
│Memory │               │ 노스   │
│       │               │브리지  │
└───────┘               └───┬───┘
                            │
              ┌─────────────┴─────────────┐
              │       PCIe 버스           │
              └─────────────┬─────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
    ┌───┴───┐           ┌───┴───┐           ┌───┴───┐
    │  GPU  │           │ NVMe  │           │사우스 │
    │       │           │  SSD  │           │브리지 │
    └───────┘           └───────┘           └───┬───┘
                                                │
                                    ┌───────────┴───────────┐
                                    │  USB, SATA, 오디오   │
                                    └───────────────────────┘
```

### 주요 인터페이스 ◑

| 인터페이스 | 용도 | 대역폭 |
|------------|------|--------|
| **PCIe 4.0 x16** | GPU, NVMe | ~32 GB/s |
| **PCIe 5.0 x16** | 차세대 GPU | ~64 GB/s |
| **PCIe 6.0 x16** | 차차세대 | ~128 GB/s |
| **NVMe** | SSD | PCIe 기반 (~7 GB/s) |
| **SATA III** | HDD/SSD (레거시) | ~600 MB/s |
| **USB 3.2 Gen 2x2** | 주변기기 | ~20 Gbps |
| **Thunderbolt 4** | 고속 주변기기 | ~40 Gbps |
| **CXL** | 메모리 확장 | PCIe 기반 |

### ⭕ 인터럽트 (Interrupt)란?

CPU가 현재 작업을 중단하고 우선 처리해야 할 이벤트를 알리는 신호이다.

```
인터럽트 처리 흐름:

실행 중인 프로그램
        │
        ▼
   ┌─────────┐
   │ 인터럽트 │ ◀── 하드웨어 신호 또는 소프트웨어 트랩
   │  발생   │
   └────┬────┘
        │
        ▼
   ┌─────────┐
   │ 상태 저장 │  (레지스터, PC, 플래그)
   └────┬────┘
        │
        ▼
   ┌─────────────────────┐
   │ 인터럽트 벡터 테이블  │  (핸들러 주소 조회)
   │  조회               │
   └────────┬────────────┘
            │
            ▼
   ┌─────────────────────┐
   │ ISR (Interrupt      │
   │ Service Routine)    │
   │ 실행                │
   └────────┬────────────┘
            │
            ▼
   ┌─────────┐
   │ 상태 복원 │
   └────┬────┘
        │
        ▼
   원래 프로그램 재개
```

| 종류 | 설명 | 예시 |
|------|------|------|
| **하드웨어 인터럽트** | 외부 장치에서 발생 | 키보드 입력, 타이머, 디스크 I/O 완료 |
| **소프트웨어 인터럽트** | 명령어로 발생 | 시스템 콜 (INT 0x80, syscall) |
| **예외 (Exception)** | 오류나 특수 상황 | 0으로 나누기, 페이지 폴트, 보호 오류 |

### ⭕ DMA (Direct Memory Access)란? ◑

CPU 개입 없이 주변장치와 메모리 간 직접 데이터 전송하는 방식이다.

```
Programmed I/O:              DMA:

CPU ───▶ 장치               CPU ─── 설정 ───▶ DMA 컨트롤러
 │                                              │
 │ (바이트마다 개입)                               │
 ▼                                              ▼
메모리                          메모리 ◀─────────▶ 장치
                                     (CPU 개입 없이 직접 전송)
```

| 방식 | 동작 | CPU 부담 |
|------|------|----------|
| Programmed I/O | CPU가 직접 전송 | 높음 |
| Interrupt-driven I/O | 인터럽트 기반 | 중간 |
| **DMA** | DMA 컨트롤러가 전송 | 낮음 |

**DMA 동작 과정:**
1. CPU가 DMA 컨트롤러에 전송 명령 (시작 주소, 크기, 방향)
2. DMA 컨트롤러가 버스 제어권 획득
3. 장치와 메모리 간 직접 데이터 전송
4. 전송 완료 시 인터럽트로 CPU에 알림

---

## 11. 고급 CPU 기술 ◑

### ⭕ SMT/하이퍼스레딩이란? ◑

SMT (Simultaneous Multi-Threading)는 하나의 물리 코어에서 여러 스레드를 동시에 실행하는 기술이다. Intel에서는 Hyper-Threading이라고 부른다.

```
물리 코어 1개, 논리 코어 2개 (SMT/HT):

┌─────────────────────────────────────────────────────┐
│                    물리 코어                         │
│  ┌─────────────────┐    ┌─────────────────┐        │
│  │ 스레드 1 상태    │    │ 스레드 2 상태    │        │
│  │ (레지스터 세트)  │    │ (레지스터 세트)  │        │
│  └────────┬────────┘    └────────┬────────┘        │
│           │                      │                  │
│           └──────────┬───────────┘                  │
│                      │                              │
│           ┌──────────▼───────────┐                  │
│           │    공유 실행 자원     │                  │
│           │  (ALU, FPU, 캐시)     │                  │
│           └──────────────────────┘                  │
└─────────────────────────────────────────────────────┘

OS는 2개의 논리 코어로 인식
```

**원리:**
- 하나의 스레드가 메모리 대기 등으로 스톨되면 다른 스레드 실행
- 실행 유닛의 활용도를 높임

| 구분 | 물리 코어 | SMT/HT |
|------|-----------|--------|
| 실행 유닛 | 완전히 독립 | 공유 |
| 레지스터 | 완전히 독립 | 각 스레드별 세트 |
| 캐시 | 완전히 독립 | 공유 (경쟁) |
| 성능 향상 | N배 | ~20-30% (워크로드 의존) |

**사용 사례:**
- 서버: 동시 처리량 증가
- 클라이언트: 멀티태스킹 성능 향상

### ⭕ 엔디안 (Endianness)이란? ◑

멀티바이트 데이터를 메모리에 저장하는 바이트 순서이다.

```
예: 0x12345678 (4바이트) 저장

Big Endian (MSB First):          Little Endian (LSB First):

주소     메모리                    주소     메모리
0x00    │  0x12  │  (MSB)         0x00    │  0x78  │  (LSB)
0x01    │  0x34  │                0x01    │  0x56  │
0x02    │  0x56  │                0x02    │  0x34  │
0x03    │  0x78  │  (LSB)         0x03    │  0x12  │  (MSB)

Big: 사람이 읽는 순서           Little: 낮은 주소에 낮은 바이트
```

| 구분 | Big Endian | Little Endian |
|------|------------|---------------|
| 바이트 순서 | MSB가 낮은 주소 | LSB가 낮은 주소 |
| 사용 | 네트워크 (Network Byte Order), PowerPC, SPARC | x86, ARM (기본), RISC-V |
| 장점 | 디버깅 직관적 | 캐스팅 시 주소 불변 |

**Bi-Endian:**
- ARM, RISC-V는 설정으로 엔디안 변경 가능
- 하지만 대부분 Little Endian으로 사용

**면접 포인트:**
- 네트워크 프로그래밍에서 `htonl()`, `ntohl()` 등 변환 함수 필요
- 파일 포맷, 통신 프로토콜에서 엔디안 명시 필요

### TLB (Translation Lookaside Buffer) ◑

가상 주소 → 물리 주소 변환을 캐싱하는 버퍼이다. 페이지 테이블 접근을 줄여 성능을 높인다.

```
가상 주소 변환 흐름:

┌──────────────┐
│   가상 주소   │
└──────┬───────┘
       │
       ▼
  ┌─────────┐    Hit    ┌─────────────┐
  │   TLB   │ ─────────▶ │  물리 주소   │
  └────┬────┘            └─────────────┘
       │ Miss
       ▼
┌─────────────────┐
│   페이지 테이블  │  (메모리에 있음 - 느림)
│     조회        │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  TLB 업데이트    │
│   + 물리 주소    │
└─────────────────┘
```

**TLB 구조:**

| 항목 | 설명 |
|------|------|
| 구조 | Fully Associative 또는 Set Associative |
| 크기 | L1 TLB: ~64-128 엔트리, L2 TLB: ~1000+ 엔트리 |
| 분리 | I-TLB (명령어), D-TLB (데이터) 분리 |

**TLB 미스 비용:**
- TLB 미스 → 페이지 테이블 워크 (여러 번 메모리 접근)
- 4단계 페이지 테이블: 최대 4번 메모리 접근

### NUMA (Non-Uniform Memory Access) ◑

멀티소켓 시스템에서 메모리 접근 시간이 위치에 따라 다른 구조이다.

```
NUMA 구조 (2소켓 시스템):

┌──────────────────────────────────────────────────────────┐
│                                                          │
│   ┌──────────────────┐      ┌──────────────────┐        │
│   │     Socket 0      │      │     Socket 1      │        │
│   │  ┌────┐  ┌────┐  │      │  ┌────┐  ┌────┐  │        │
│   │  │CPU │  │CPU │  │      │  │CPU │  │CPU │  │        │
│   │  │ 0  │  │ 1  │  │      │  │ 2  │  │ 3  │  │        │
│   │  └────┘  └────┘  │      │  └────┘  └────┘  │        │
│   │       │          │      │       │          │        │
│   │   ┌───┴────┐     │      │   ┌───┴────┐     │        │
│   │   │ Memory │     │ ◀──▶ │   │ Memory │     │        │
│   │   │ Node 0 │     │ QPI/ │   │ Node 1 │     │        │
│   │   └────────┘     │ UPI  │   └────────┘     │        │
│   └──────────────────┘      └──────────────────┘        │
│                                                          │
│   Local Access: ~80ns         Remote Access: ~150ns     │
└──────────────────────────────────────────────────────────┘
```

| 접근 타입 | 설명 | 지연 시간 |
|-----------|------|-----------|
| **Local** | 같은 노드의 메모리 | 빠름 (~1x) |
| **Remote** | 다른 노드의 메모리 | 느림 (~1.5-2x) |

**NUMA 최적화:**
- 메모리 할당 시 로컬 노드 우선
- 스레드를 해당 노드에 바인딩
- OS의 NUMA-aware 스케줄링

---

## 12. 명령어 집합 구조 (ISA) ◑

### ⭕ ISA란?

Instruction Set Architecture의 약자로, 하드웨어와 소프트웨어 간의 인터페이스를 정의한다.

| 구성 요소 | 설명 |
|-----------|------|
| 명령어 종류 | 산술, 논리, 분기, 메모리 접근 등 |
| 레지스터 | 개수, 크기, 용도 |
| 주소 지정 모드 | 피연산자 위치 지정 방식 |
| 데이터 타입 | 정수, 부동소수점 등 |
| 명령어 인코딩 | 명령어 형식, 길이 |

### 주요 ISA ◑

| ISA | 특징 | 사용처 |
|-----|------|--------|
| **x86-64** | CISC, 호환성, 복잡한 디코딩 | PC, 서버 |
| **ARM** | RISC, 저전력, 라이선스 모델 | 모바일, 임베디드, Apple Silicon, 서버 (Graviton) |
| **RISC-V** | 오픈소스 RISC, 확장 가능 | 임베디드, 연구, 확대 중 |
| **MIPS** | 교육용 RISC | 학습, 일부 임베디드 |

### 주소 지정 모드 ◑

| 모드 | 설명 | 예시 |
|------|------|------|
| 즉시 (Immediate) | 피연산자가 명령어에 포함 | `MOV R1, #5` |
| 레지스터 (Register) | 레지스터에 저장된 값 | `MOV R1, R2` |
| 직접 (Direct) | 메모리 주소 직접 지정 | `MOV R1, [0x1000]` |
| 간접 (Indirect) | 레지스터에 저장된 주소 | `MOV R1, [R2]` |
| 인덱스 (Indexed) | 베이스 + 오프셋 | `MOV R1, [R2+4]` |
| 스케일 (Scaled) | 베이스 + 인덱스×스케일 | `MOV R1, [R2+R3*4]` |

---

## 면접 대비 체크리스트 ◑

- [ ] 폰 노이만 구조와 하버드 구조
- [ ] 폰 노이만 병목과 해결 방법
- [ ] 메모리 계층 구조와 각 레벨의 특성
- [ ] 캐시 지역성 (시간적, 공간적)
- [ ] 캐시 매핑 방식 (Direct, Set-Associative, Fully-Associative)
- [ ] Write-through vs Write-back
- [ ] 캐시 미스 유형 (3C)
- [ ] 캐시 일관성 (MESI 프로토콜)
- [ ] 파이프라이닝 5단계와 해저드 종류
- [ ] 분기 예측 (정적/동적, 2-bit predictor, BTB)
- [ ] 데이터 해저드 (RAW, WAR, WAW)
- [ ] 포워딩 (Bypassing)
- [ ] CISC vs RISC
- [ ] 슈퍼스칼라와 비순차 실행
- [ ] 레지스터 리네이밍, Reorder Buffer
- [ ] 컴파일 과정 6단계
- [ ] 링커와 로더의 역할
- [ ] 프로세스 메모리 구조 (Text, Data, BSS, Heap, Stack)
- [ ] CPU vs GPU 아키텍처 차이
- [ ] SRAM vs DRAM
- [ ] DDR, GDDR, HBM 차이
- [ ] 인터럽트 종류와 처리 과정
- [ ] DMA 동작 원리
- [ ] ISA와 주소 지정 모드
- [ ] PCIe, NVMe 등 주요 인터페이스
- [ ] SMT/하이퍼스레딩 (물리 코어 vs 논리 코어)
- [ ] 엔디안 (Big Endian vs Little Endian)
- [ ] TLB (Translation Lookaside Buffer)
- [ ] NUMA (Non-Uniform Memory Access)
