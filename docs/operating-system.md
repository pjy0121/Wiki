# 02. 운영체제 (Operating System)

---

## 1. 운영체제 기본 개념

### 운영체제의 역할

- 하드웨어 자원 관리 (CPU, 메모리, I/O)
- 사용자와 하드웨어 간의 인터페이스 제공
- 프로세스 관리 및 스케줄링
- 파일 시스템 관리

### 커널 (Kernel)

운영체제의 핵심으로, 하드웨어와 직접 상호작용

### ⭕ 모놀리식 커널과 마이크로커널의 차이는? ◑

| 구분 | 모놀리식 커널 | 마이크로커널 |
|------|---------------|--------------|
| 구조 | 모든 기능이 커널에 포함 | 핵심만 커널, 나머지는 유저 공간 |
| 성능 | 빠름 (시스템 콜만) | 느림 (IPC 오버헤드) |
| 안정성 | 커널 버그 → 전체 영향 | 서비스 분리로 안정적 |
| 확장성 | 재컴파일 필요 | 모듈 추가 용이 |
| 예시 | Linux, Unix, Windows | Minix, QNX, L4 |

```
모놀리식 커널:                    마이크로커널:

┌──────────────────────┐         ┌──────────────────────┐
│      User Space      │         │      User Space      │
│  ┌────┐  ┌────┐     │         │  ┌────┐  ┌────┐     │
│  │App1│  │App2│     │         │  │App │  │FS  │     │
│  └────┘  └────┘     │         │  └────┘  └────┘     │
├──────────────────────┤         │  ┌────┐  ┌────┐     │
│      Kernel Space    │         │  │Net │  │Driver│   │
│  ┌─────────────────┐ │         │  └────┘  └────┘     │
│  │ 프로세스 관리    │ │         ├──────────────────────┤
│  │ 메모리 관리      │ │         │   Microkernel       │
│  │ 파일 시스템      │ │         │  ┌───────────────┐  │
│  │ 네트워크 스택    │ │         │  │ IPC, 스케줄링 │  │
│  │ 디바이스 드라이버│ │         │  │ 기본 메모리   │  │
│  └─────────────────┘ │         │  └───────────────┘  │
└──────────────────────┘         └──────────────────────┘
```

**하이브리드 커널:**
- macOS, Windows NT는 하이브리드 방식 채택
- 마이크로커널 구조 + 성능 위해 일부 서비스를 커널에 포함

### 시스템 콜 (System Call)

사용자 프로그램이 커널의 서비스를 요청하는 인터페이스

**주요 시스템 콜:**
- 프로세스: `fork()`, `exec()`, `exit()`, `wait()`
- 파일: `open()`, `read()`, `write()`, `close()`
- 메모리: `mmap()`, `brk()`

### 인터럽트 (Interrupt)

- **하드웨어 인터럽트**: 외부 장치에서 발생 (키보드, 타이머)
- **소프트웨어 인터럽트**: 프로그램에서 발생 (시스템 콜, 예외)

### ⭕ User Mode와 Kernel Mode의 차이는? ◑

| 구분 | User Mode | Kernel Mode |
|------|-----------|-------------|
| 권한 | 제한적 (Ring 3) | 전체 (Ring 0) |
| 하드웨어 접근 | 시스템 콜 통해서만 | 직접 가능 |
| 메모리 접근 | 자신의 주소 공간만 | 전체 메모리 |
| 오류 영향 | 해당 프로세스만 종료 | 시스템 전체 영향 |

**모드 전환:** 시스템 콜, 인터럽트, 예외 발생 시 User → Kernel 전환

---

## 2. 프로세스 관리

### ⭕ 프로세스와 스레드의 차이는?

| 구분 | 프로세스 | 스레드 |
|------|----------|--------|
| 정의 | 실행 중인 프로그램 | 프로세스 내 실행 단위 |
| 메모리 | 독립적인 주소 공간 | 프로세스 내 공유 (스택만 독립) |
| 통신 | IPC 필요 | 공유 메모리로 직접 통신 |
| 생성 비용 | 높음 | 낮음 |
| 컨텍스트 스위칭 | 비용 높음 | 비용 낮음 |

```
프로세스 A                    프로세스 B
┌─────────────┐              ┌─────────────┐
│    Code     │              │    Code     │
│    Data     │  ← 독립 →    │    Data     │
│    Heap     │              │    Heap     │
│    Stack    │              │    Stack    │
└─────────────┘              └─────────────┘

        프로세스 (멀티스레드)
┌──────────────────────────────────┐
│  Code  │  Data  │      Heap      │  ← 공유
├────────┴────────┴────────────────┤
│ Stack1 │ Stack2 │ Stack3 │ ...   │  ← 스레드별 독립
└──────────────────────────────────┘
```

### PCB (Process Control Block)

프로세스 정보를 저장하는 자료구조

**PCB 포함 정보:**
- 프로세스 상태 (State)
- 프로그램 카운터 (PC)
- 레지스터 값
- CPU 스케줄링 정보
- 메모리 관리 정보
- I/O 상태 정보

### 프로세스 상태

```
        생성                    완료
         │                       ↑
         ▼                       │
      [Ready] ──dispatch──▶ [Running]
         ↑                       │
         │                       │
    admitted            interrupt/timeout
         │                       │
         │      ◀──────────────┘
         │
      I/O 완료
         │
      [Waiting] ◀── I/O 요청 ───┘
```

### ⭕ 컨텍스트 스위칭이란?

CPU가 한 프로세스에서 다른 프로세스로 전환할 때 발생하는 과정

**과정:**
1. 현재 프로세스 상태 저장 (PCB에)
2. 다음 프로세스 상태 복원 (PCB에서)
3. 새 프로세스 실행

**오버헤드:** 순수 오버헤드로, 이 시간 동안 유용한 작업 수행 불가

### ⭕ fork()와 exec()를 설명하라 ◑

**fork():**
- 현재 프로세스를 복제하여 자식 프로세스 생성
- 부모와 자식은 별도의 메모리 공간 (Copy-on-Write로 최적화)
- 반환값: 부모는 자식의 PID, 자식은 0

**exec():**
- 현재 프로세스를 새 프로그램으로 대체
- PID는 유지, 코드/데이터/힙/스택이 새 프로그램으로 교체

```c
pid_t pid = fork();

if (pid == 0) {
    // 자식 프로세스
    exec("/bin/ls", ...);  // 새 프로그램으로 대체
} else {
    // 부모 프로세스
    wait(NULL);  // 자식 종료 대기
}
```

```
fork() + exec() 흐름:

부모 프로세스               자식 프로세스
┌─────────────┐
│   Code A    │
│   Data A    │
└──────┬──────┘
       │ fork()
       ├─────────────────▶ ┌─────────────┐
       │                   │   Code A    │ (복사됨)
       │                   │   Data A    │
       │                   └──────┬──────┘
       │                          │ exec()
       │                          ▼
       │                   ┌─────────────┐
       │                   │   Code B    │ (새 프로그램)
       │                   │   Data B    │
       │                   └─────────────┘
       │ wait()
       ▼
```

### ⭕ Copy-on-Write (COW)란? ◑

fork() 시 메모리를 즉시 복사하지 않고, 실제 쓰기가 발생할 때만 복사하는 기법이다.

```
fork() 직후 (COW):

부모 페이지 테이블          자식 페이지 테이블
┌─────────────┐            ┌─────────────┐
│   Page 1 ───┼────────────┼──▶ Frame A  │  (공유, 읽기 전용)
│   Page 2 ───┼────────────┼──▶ Frame B  │
│   Page 3 ───┼────────────┼──▶ Frame C  │
└─────────────┘            └─────────────┘

자식이 Page 2 수정 시:

부모 페이지 테이블          자식 페이지 테이블
┌─────────────┐            ┌─────────────┐
│   Page 1 ───┼──▶ Frame A │──▶ Frame A  │  (계속 공유)
│   Page 2 ───┼──▶ Frame B │──▶ Frame B' │  (복사 후 수정)
│   Page 3 ───┼──▶ Frame C │──▶ Frame C  │  (계속 공유)
└─────────────┘            └─────────────┘
```

**장점:**
- fork() 속도 대폭 향상 (즉시 복사 불필요)
- 메모리 사용량 감소 (읽기만 하면 공유 유지)
- exec() 바로 호출 시 복사 거의 불필요

### ⭕ 좀비 프로세스와 고아 프로세스의 차이는? ◑

| 구분 | 좀비 프로세스 | 고아 프로세스 |
|------|---------------|---------------|
| 정의 | 종료되었지만 부모가 wait() 안 함 | 부모가 먼저 종료됨 |
| 상태 | 종료됨, PCB만 남음 | 실행 중 |
| 문제 | PID, 리소스 누수 | 보통 문제 없음 |
| 해결 | 부모가 wait() 호출 | init(PID 1)이 입양 |

```
좀비 프로세스:

부모 프로세스            자식 프로세스
┌─────────────┐         ┌─────────────┐
│  Running    │         │  Running    │
│             │         └──────┬──────┘
│  wait()     │                │ exit()
│  안 호출    │                ▼
│             │         ┌─────────────┐
│             │         │   Zombie    │ ← 종료 상태, PCB만 유지
└─────────────┘         │ (defunct)   │
                        └─────────────┘

고아 프로세스:

부모 프로세스            자식 프로세스
┌─────────────┐         ┌─────────────┐
│  Running    │         │  Running    │
└──────┬──────┘         │             │
       │ exit()         │             │
       ▼                │             │
   (종료됨)             │             │
                        └──────┬──────┘
                               │ 입양
                        ┌──────▼──────┐
                        │ init (PID 1) │
                        └─────────────┘
```

**좀비 프로세스 방지:**
- 부모에서 `wait()` 또는 `waitpid()` 호출
- `SIGCHLD` 시그널 핸들러에서 처리
- 자식을 double fork로 생성 (손자를 init에 입양)

---

## 3. CPU 스케줄링

### 스케줄링 목표

- CPU 활용률 최대화
- 처리량 (Throughput) 최대화
- 응답 시간 최소화
- 대기 시간 최소화
- 공정성 보장

### 비선점 스케줄링

| 알고리즘 | 설명 | 장점 | 단점 |
|----------|------|------|------|
| **FCFS** (First Come First Served) | 도착 순서대로 처리 | 단순, 공정 | Convoy Effect |
| **SJF** (Shortest Job First) | 실행 시간 짧은 것 우선 | 평균 대기 시간 최소 | 기아 현상, 실행 시간 예측 어려움 |

### 선점 스케줄링

| 알고리즘 | 설명 | 장점 | 단점 |
|----------|------|------|------|
| **Round Robin** | 타임 퀀텀만큼 돌아가며 실행 | 응답 시간 보장, 공정 | 컨텍스트 스위칭 오버헤드 |
| **SRTF** (Shortest Remaining Time First) | 남은 시간 짧은 것 우선 | 평균 대기 시간 최소 | 기아 현상 |
| **Priority** | 우선순위 기반 | 중요한 작업 우선 처리 | 기아 현상 (Aging으로 해결) |
| **Multilevel Queue** | 여러 큐를 우선순위별로 관리 | 다양한 작업 유형 처리 | 복잡함 |

> **Note:** Priority 스케줄링은 비선점 방식으로도 구현 가능하나, 일반적으로 선점형이 많이 사용된다.

---

## 4. 메모리 관리

### ⭕ 프로세스 메모리 레이아웃을 설명하라 ◑

프로세스가 메모리에 적재될 때 다음과 같은 구조로 배치된다.

```
높은 주소
┌─────────────────────────┐
│        Stack            │  ← 지역 변수, 함수 매개변수, 리턴 주소
│          ↓              │     (높은 주소 → 낮은 주소로 성장)
│                         │
│          ↑              │
│         Heap            │  ← 동적 할당 (malloc, new)
│                         │     (낮은 주소 → 높은 주소로 성장)
├─────────────────────────┤
│    BSS (Uninitialized)  │  ← 초기화되지 않은 전역/정적 변수
├─────────────────────────┤
│    Data (Initialized)   │  ← 초기화된 전역/정적 변수
├─────────────────────────┤
│    Text (Code)          │  ← 실행 코드 (읽기 전용)
└─────────────────────────┘
낮은 주소
```

| 영역 | 내용 | 특징 |
|------|------|------|
| **Text (Code)** | 컴파일된 프로그램 코드 | 읽기 전용, 공유 가능 |
| **Data** | 초기화된 전역/정적 변수 | `int g = 10;` |
| **BSS** | 초기화되지 않은 전역/정적 변수 | `int g;` (0으로 초기화) |
| **Heap** | 동적 할당 메모리 | `malloc()`, `new` |
| **Stack** | 함수 호출 정보, 지역 변수 | 자동 할당/해제, LIFO |

**스택 프레임 (Stack Frame):**
```
┌─────────────────────────┐
│      리턴 주소           │
├─────────────────────────┤
│    이전 프레임 포인터 (FP) │
├─────────────────────────┤
│      매개변수            │
├─────────────────────────┤
│      지역 변수           │
└─────────────────────────┘
```

**힙과 스택의 차이:**

| 구분 | Stack | Heap |
|------|-------|------|
| 할당 방식 | 컴파일 시 결정, 자동 | 런타임에 동적 할당 |
| 해제 방식 | 자동 (스코프 종료 시) | 수동 (`free`, `delete`) |
| 속도 | 빠름 | 상대적으로 느림 |
| 크기 | 제한적 (스택 오버플로우) | 상대적으로 큼 |
| 성장 방향 | 높은 주소 → 낮은 주소 | 낮은 주소 → 높은 주소 |

**관련 문제:**
- **스택 오버플로우**: 스택 공간 초과 (재귀 호출 과다)
- **힙 오버플로우**: 힙 영역 버퍼 경계 초과 쓰기
- **메모리 누수**: 힙 메모리 해제 누락

---

### 페이징 (Paging)

물리 메모리를 프레임이라는 블록으로 나누고 프로세스의 논리 주소 공간을 페이지로 매핑하는 기법

- **페이지**: 논리 주소 공간의 블록
- **프레임**: 물리 메모리의 블록
- **페이지 테이블**: 페이지 → 프레임 매핑 정보

### TLB (Translation Lookaside Buffer)

페이지 테이블의 캐시로, 주소 변환 속도 향상

### ⭕ 페이지 교체 알고리즘의 종류와 특징은?

| 알고리즘 | 설명 | 특징 |
|----------|------|------|
| **FIFO** | 가장 오래된 페이지 교체 | 단순하지만 Belady's Anomaly 발생 가능 |
| **LRU** | 가장 오래 사용 안 된 페이지 교체 | 성능 좋음, 구현 복잡 |
| **LFU** | 가장 적게 사용된 페이지 교체 | 최근 적재된 페이지에 불리 |
| **Optimal** | 가장 오래 사용 안 될 페이지 교체 | 이론적 최적, 실제 구현 불가 |

### 세그멘테이션 (Segmentation)

논리적 단위(코드, 데이터, 스택)로 메모리 분할

### ⭕ 내부 단편화와 외부 단편화의 차이는? ◑

| 구분 | 내부 단편화 | 외부 단편화 |
|------|-------------|-------------|
| 정의 | 할당된 공간 내 미사용 영역 | 할당되지 않은 작은 조각들 |
| 발생 | 페이징 (고정 크기 할당) | 세그멘테이션 (가변 크기 할당) |
| 해결 | 페이지 크기 조절 | 압축(Compaction), 페이징 |

### 가상 메모리

물리 메모리보다 큰 주소 공간 제공, 요구 페이징으로 필요한 페이지만 메모리에 적재

### ⭕ 스래싱(Thrashing)이란? ◑

프로세스가 실제 작업보다 페이지 스왑에 더 많은 시간을 소비하는 현상이다.

**원인:**
- 멀티프로그래밍 정도가 너무 높음
- 각 프로세스의 Working Set을 수용할 메모리 부족

**해결 방법:**
- Working Set Model: 프로세스의 활성 페이지 집합 유지
- Page Fault Frequency 조절: 페이지 폴트율 모니터링으로 메모리 할당 조정
- 멀티프로그래밍 정도 감소

---

## 5. 동기화

### 경쟁 조건 (Race Condition)

여러 프로세스/스레드가 공유 자원에 동시 접근하여 결과가 접근 순서에 따라 달라지는 상황

### 임계 구역 (Critical Section)

공유 자원에 접근하는 코드 영역

**임계 구역 문제 해결 조건:**
1. **상호 배제 (Mutual Exclusion)**: 한 번에 하나만 접근
2. **진행 (Progress)**: 대기 중인 프로세스가 진입 가능
3. **한정 대기 (Bounded Waiting)**: 무한 대기 방지

### ⭕ Mutex와 Semaphore의 차이는?

| 구분 | Mutex | Semaphore |
|------|-------|-----------|
| 값 | 0 또는 1 | 0 이상 정수 |
| 소유권 | 락을 획득한 스레드만 해제 가능 | 어떤 스레드든 signal 가능 |
| 용도 | 상호 배제 | 상호 배제 + 리소스 카운팅 |

### ⭕ Spinlock이란? ◑

락을 획득할 때까지 반복적으로 확인(busy-waiting)하는 동기화 기법이다.

| 구분 | Spinlock | Mutex |
|------|----------|-------|
| 대기 방식 | Busy-waiting (CPU 사용) | Sleep (블로킹) |
| 적합한 경우 | 짧은 대기, 멀티코어 | 긴 대기, 컨텍스트 스위칭 감수 |
| 오버헤드 | 컨텍스트 스위칭 없음 | 컨텍스트 스위칭 발생 |

---

## 6. 데드락

### ⭕ 데드락 발생 조건과 해결 방법은?

**4가지 조건 (모두 충족 시 발생):**
1. **상호 배제 (Mutual Exclusion)**: 자원을 배타적으로 사용
2. **점유와 대기 (Hold and Wait)**: 자원을 보유한 채 다른 자원 대기
3. **비선점 (No Preemption)**: 자원을 강제로 빼앗을 수 없음
4. **순환 대기 (Circular Wait)**: 프로세스 간 순환 형태의 대기

```
예시: 식사하는 철학자 문제 (Dining Philosophers)

철학자 5명이 원탁에 앉아 있고, 각자 왼쪽과 오른쪽 포크가 필요함

    철학자1 ──(포크1 보유, 포크2 대기)──▶ 철학자2
       ▲                                    │
       │                              (포크2 보유, 포크3 대기)
       │                                    ▼
    철학자5 ◀── ... ◀── 철학자4 ◀── 철학자3

모든 철학자가 왼쪽 포크를 집고 오른쪽 포크를 기다리면 → 데드락!
```

**해결 방법:**

| 방법 | 설명 |
|------|------|
| 예방 (Prevention) | 4가지 조건 중 하나를 원천 차단 |
| 회피 (Avoidance) | 안전 상태 유지 (은행원 알고리즘) |
| 탐지 (Detection) | 데드락 발생 감지 후 복구 |
| 무시 (Ignorance) | 발생 빈도 낮으면 무시 (실제 많이 사용) |

### 은행원 알고리즘 (Banker's Algorithm)

자원 할당 전 시스템이 안전 상태인지 확인하여 데드락 회피

---

## 7. 프로세스 간 통신 (IPC) ◑

### ⭕ IPC (Inter-Process Communication)란?

프로세스 간 데이터를 주고받는 메커니즘이다. 프로세스는 독립된 메모리 공간을 가지므로 직접 통신이 불가능하다.

### IPC 방법 비교 ◑

| 방법 | 설명 | 특징 |
|------|------|------|
| **Pipe** | 단방향 데이터 흐름 | 부모-자식 프로세스 간, 익명 파이프 |
| **Named Pipe (FIFO)** | 이름 있는 파이프 | 관계없는 프로세스 간 통신 |
| **Message Queue** | 메시지 단위 통신 | 비동기, 우선순위 지원 |
| **Shared Memory** | 메모리 영역 공유 | 가장 빠름, 동기화 필요 |
| **Socket** | 네트워크 통신 | 로컬/원격 모두 가능 |
| **Signal** | 비동기 알림 | 간단한 이벤트 전달 |

### ⭕ Pipe와 Shared Memory의 차이는? ◑

| 구분 | Pipe | Shared Memory |
|------|------|---------------|
| 데이터 복사 | 커널 버퍼 경유 (2회 복사) | 없음 (직접 접근) |
| 속도 | 상대적으로 느림 | 가장 빠름 |
| 동기화 | 자동 (blocking I/O) | 수동 (세마포어 필요) |
| 방향 | 단방향 | 양방향 |

### Socket 통신 ◑

| 종류 | 설명 |
|------|------|
| **Unix Domain Socket** | 같은 호스트 내 프로세스 간 통신 |
| **Internet Socket** | 네트워크를 통한 원격 통신 (TCP/UDP) |

---

## 8. I/O와 저장장치

### I/O 처리 방식

| 방식 | 설명 |
|------|------|
| **Polling** | CPU가 주기적으로 상태 확인 |
| **Interrupt** | I/O 완료 시 인터럽트 발생 |
| **DMA** | CPU 개입 없이 메모리 직접 접근 |

### 디스크 스케줄링

| 알고리즘 | 설명 |
|----------|------|
| **FCFS** | 요청 순서대로 처리 |
| **SSTF** | 현재 위치에서 가장 가까운 요청 처리 |
| **SCAN** | 한 방향으로 끝까지 이동 후 반대 방향 |
| **C-SCAN** | 한 방향으로만 서비스, 끝에서 시작점으로 이동 |

---

## 9. 파일 시스템 ◑

### 파일 시스템 구조

| 구성 요소 | 설명 |
|-----------|------|
| Boot Block | 부팅에 필요한 코드 |
| Superblock | 파일 시스템 메타데이터 (블록 크기, 총 블록 수 등) |
| Inode Table | 파일 메타데이터 (권한, 크기, 블록 포인터) |
| Data Blocks | 실제 파일 데이터 |

### Inode (Index Node)

파일의 메타데이터를 저장하는 자료구조 (파일명 제외)

**포함 정보:** 파일 크기, 소유자, 권한, 타임스탬프, 데이터 블록 포인터

### ⭕ 하드 링크와 심볼릭 링크의 차이는?

| 구분 | 하드 링크 | 심볼릭 링크 |
|------|-----------|-------------|
| 참조 대상 | 같은 inode | 경로 문자열 |
| 원본 삭제 시 | 접근 가능 | 깨진 링크 |
| 파일 시스템 | 동일 파일 시스템만 | 다른 파일 시스템 가능 |
| 디렉터리 링크 | 불가 | 가능 |

### 저널링 (Journaling) ◑

파일 시스템 변경 전 로그를 기록하여 비정상 종료 시 복구 가능

---

## 면접 대비 체크리스트 ◑

- [ ] User Mode vs Kernel Mode
- [ ] 모놀리식 커널 vs 마이크로커널
- [ ] 프로세스 vs 스레드
- [ ] 컨텍스트 스위칭 과정
- [ ] fork()와 exec() 동작
- [ ] Copy-on-Write (COW)
- [ ] 좀비 프로세스 vs 고아 프로세스
- [ ] CPU 스케줄링 알고리즘 (FCFS, SJF, RR, SRTF)
- [ ] 프로세스 메모리 레이아웃 (Text, Data, BSS, Heap, Stack)
- [ ] 스택 vs 힙 차이
- [ ] 페이징과 TLB
- [ ] 페이지 교체 알고리즘 (FIFO, LRU, LFU, Optimal)
- [ ] 내부 단편화 vs 외부 단편화
- [ ] 스래싱과 Working Set
- [ ] Mutex vs Semaphore vs Spinlock
- [ ] 임계 구역 해결 조건 3가지
- [ ] 데드락 4가지 조건과 해결 방법
- [ ] IPC 방법 (Pipe, Shared Memory, Socket)
- [ ] 하드 링크 vs 심볼릭 링크
